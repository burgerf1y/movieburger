## crawler
crawler会对豆瓣Top250电影的用户评分信息进行爬取，由三个python文件组成。
### get_top250.py
逐页访问豆瓣Top250电影的页面，使用requests + bs4爬取250部电影的简体中文名称和id，并将结果保存在data目录下的top250.csv文件中。
### get_user.py
为了获取足够数量的用户id，我们采用的方法是给定一个起始用户，递归地查找其关注的用户和其粉丝，从而能迅速地获得海量的用户id。

上述过程的难点在于需要登录豆瓣才可以查看用户的关注列表和粉丝列表。为此，我们使用了selenium中的webdriver来模拟真实浏览器的行为。登录豆瓣可能涉及到输入账号密码、拖动滑块、手机APP扫码等等步骤，其中输入账号密码可以用webdriver中的send()实现，拖动滑块可以用webdriver中的ActionChains实现。由于程序拖动滑块的准确率不高，所以get_user.py将整个登录的过程都交给聪明的你自行完成。聪明的你登录成功后，只需要在终端输入任何字符，程序便会开始递归执行，直到搜索到足够数量的用户id，写入data目录下的user.csv文件。
### get_rating.py
对于get_user.py中得到的用户进行遍历，选择看过五十部以上的电影、且评分过十部以上Top250电影的用户的评分进行记录，写入data目录下的user_rating.csv文件。上述过程使用了强大的re库，可以跳出html文件的格式限制，非常灵活。

由于逐一访问用户的电影评分的工作量是巨大的，故get_rating.py还会维护一个user_passed.csv文件，记录哪些用户的电影评分已经被记录过了，便于程序分多次执行。